{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Dependencies\n",
    "    - envoy\n",
    "    - progressbar\n",
    "    - sklearn 0.17\n",
    "    - Cython\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lrec.utils.data_utils.data import Data, loadDataset\n",
    "from lrec.utils.data_utils.lineParser import UserItemRatingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = TRAIN_DATA_PATH\n",
    "test_path = TEST_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data format:\n",
    "    <user_id>\\t<item_id>\\t<rating>\n",
    "    Note: \"rating\" is 1 for one class collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the dataset parser\n",
    "parser = UserItemRatingParser(delim=\"\\t\")\n",
    "d = Data()\n",
    "d.import_data(train_path, parser)\n",
    "train = d.R\n",
    "test, _ = loadDataset(test_path, d.users, d.items, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Learn LRec Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Learn model in parallel</h3>\n",
    "Start ipython parallel engines.\n",
    "\n",
    "For eg: start 4 ipython engines\n",
    "\n",
    "ipcluster start -n 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions\n",
    "   - squared : squared loss \n",
    "   - squared_analytical : squared loss solved analytically. Preferred when user-user matrix can fit into the memory\n",
    "   - logistic: logistic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lrec.recommender.LRec.LRec import LRec\n",
    "from lrec.recommender.modelArgs import LRecArgs\n",
    "from lrec.evaluate.eval_ranking_metric import evalMetricsParallelMiniBatch\n",
    "\n",
    "#number of cpu to use\n",
    "n = 4\n",
    "#set loss function (squared or logisitc)\n",
    "loss = \"logistic\"\n",
    "#set regularization strength\n",
    "c = 0.0001\n",
    "arg = LRecArgs(c, loss)\n",
    "model = LRec(arg)\n",
    "indices, sim = model.fit_parallel(train,num_procs=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluate the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lrec.evaluate.eval_ranking_metric import evalMetricsParallelMiniBatch\n",
    "evalMetricsParallelMiniBatch(train, train, test, model, mapk=100, ks=[3, 5, 10, 20])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
